{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install yt-dlp","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport subprocess\nfrom IPython.display import Audio, display\nimport librosa\n\ndef download_and_play_youtube_audio(url, output_path=\"output.mp3\"):\n    try:\n        # Use yt-dlp to download the audio\n        subprocess.run([\n            'yt-dlp',\n            '-x', '--audio-format', 'mp3',\n            '-o', 'temp_audio.%(ext)s',\n            url\n        ], check=True)\n\n        temp_file = \"temp_audio.mp3\"\n\n        # Convert to the desired output path if needed\n        if output_path != temp_file:\n            os.rename(temp_file, output_path)\n\n        # Load the audio file using librosa\n        audio_data, sr = librosa.load(output_path, sr=None)\n\n        # Display audio player in Kaggle notebook\n        print(f\"Playing audio from: {output_path}\")\n        display(Audio(audio_data, rate=sr))\n\n        return True\n\n    except Exception as e:\n        print(f\"Error: {str(e)}\")\n\nurl = input(\"SENIORS PLZ ENTER THE YOUTUBE URL:\")\ndownload_and_play_youtube_audio(url, \"output.mp3\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install openai-whisper\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import whisper\n\ndef transcribe_audio_with_whisper(audio_path):\n    try:\n        # Load the Whisper model\n        model = whisper.load_model(\"base\")\n\n        # Transcribe the audio directly using Whisper \n        result = model.transcribe(audio_path)\n\n        # Return the transcribed text instead of printing directly\n        return result['text']\n\n    except Exception as e:\n        print(f\"Error: {str(e)}\")\n        return None\n\n# Call the function with the audio path after downloading\naudio_path = \"output.mp3\"  # Path to your downloaded audio file\ntranscription = transcribe_audio_with_whisper(audio_path)\n\n# Print the transcription explicitly here\nif transcription:\n    print(f\"Transcription: {transcription}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The transcription needs to be split into segments with timestamps so that you can overlay them on the video. Each subtitle block in an SRT file includes:\n\nA sequence number.\nA timestamp (start and end times).\nThe transcribed text.\nSRT:SubRip Subtitle format","metadata":{}},{"cell_type":"markdown","source":"Overlay Subtitles Using FFmpeg: After generating the SRT file,  use FFmpeg to merge the subtitles with your video.","metadata":{}},{"cell_type":"code","source":"import os\n\ndef create_srt_file(transcription_result, srt_path=\"subtitles.srt\"):\n    try:\n        segments = transcription_result['segments']  # Whisper provides timestamps here\n        with open(srt_path, \"w\", encoding=\"utf-8\") as srt_file:\n            for idx, segment in enumerate(segments):\n                start_time = segment['start']\n                end_time = segment['end']\n                text = segment['text']\n\n                # Format time as hh:mm:ss,ms\n                def format_time(seconds):\n                    hours = int(seconds // 3600)\n                    minutes = int((seconds % 3600) // 60)\n                    seconds = int(seconds % 60)\n                    milliseconds = int((seconds - int(seconds)) * 1000)\n                    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n\n                srt_file.write(f\"{idx + 1}\\n\")\n                srt_file.write(f\"{format_time(start_time)} --> {format_time(end_time)}\\n\")\n                srt_file.write(f\"{text.strip()}\\n\\n\")\n\n        print(f\"Subtitle file saved to: {srt_path}\")\n        return srt_path\n\n    except Exception as e:\n        print(f\"Error creating SRT file: {str(e)}\")\n        return None\n\n# Example usage\naudio_path = \"output.mp3\"\ntranscription_result = whisper.load_model(\"base\").transcribe(audio_path)\nif transcription_result:\n    srt_path = create_srt_file(transcription_result)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_srt_file(srt_path):\n    try:\n        with open(srt_path, \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n            print(content)\n    except Exception as e:\n        print(f\"Error reading SRT file: {str(e)}\")\n\n# Example usage\nsrt_path = \"subtitles.srt\"\nread_srt_file(srt_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\n\ndef download_video(url, output_path=\"input_video.mp4\"):\n    try:\n        subprocess.run([\n            'yt-dlp',\n            '-f', 'bestvideo+bestaudio',\n            '--merge-output-format', 'mp4',\n            '-o', output_path,\n            url\n        ], check=True)\n        print(f\"Video downloaded successfully: {output_path}\")\n    except Exception as e:\n        print(f\"Error downloading video: {str(e)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"download_video(url)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\n\ndef overlay_subtitles(video_path, srt_path, output_path=\"output_video.mp4\"):\n    try:\n        # Use FFmpeg to overlay subtitles\n        subprocess.run([\n            'ffmpeg',\n            '-i', video_path,\n            '-vf', f\"subtitles={srt_path}\",\n            '-c:a', 'copy',\n            output_path\n        ], check=True)\n        print(f\"Subtitled video saved as: {output_path}\")\n        return output_path\n    except Exception as e:\n        print(f\"Error adding subtitles: {str(e)}\")\n        return None\n\n# Example usage\nvideo_path = \"input_video.mp4\"  # Your downloaded video\nsrt_path = \"subtitles.srt\"      # Your generated subtitle file\noverlay_subtitles(video_path, srt_path)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls   #The output lists the files and directories present in the current working directory of your notebook.\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import Video\n\n# Path to your video file\nvideo_path = \"output_video.mp4\"\n\n# Display the video\nVideo(video_path, embed=True, width=640, height=360)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}